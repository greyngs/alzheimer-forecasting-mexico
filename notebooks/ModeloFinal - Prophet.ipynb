{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3bea63c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dateutil.easter\n",
    "from prophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3633a3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Week</th>\n",
       "      <th>Date</th>\n",
       "      <th>Epi_Year</th>\n",
       "      <th>total_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>2014-01-13</td>\n",
       "      <td>2014</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>2014-01-20</td>\n",
       "      <td>2014</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>2014-01-27</td>\n",
       "      <td>2014</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>2014-02-03</td>\n",
       "      <td>2014</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>2014-02-10</td>\n",
       "      <td>2014</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Week        Date  Epi_Year  total_cases\n",
       "0  2014     2  2014-01-13      2014          4.0\n",
       "1  2014     3  2014-01-20      2014         29.0\n",
       "2  2014     4  2014-01-27      2014         47.0\n",
       "3  2014     5  2014-02-03      2014         36.0\n",
       "4  2014     6  2014-02-10      2014         42.0"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_national = pd.read_csv(\n",
    "    '../data/processed/data_processed_v3_National_NoAcum_Total.csv')\n",
    "df_national.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fe663b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame prepared for Prophet - Head:\n",
      "   Year  Week         ds  Epi_Year     y\n",
      "0  2014     2 2014-01-13      2014   4.0\n",
      "1  2014     3 2014-01-20      2014  29.0\n",
      "2  2014     4 2014-01-27      2014  47.0\n",
      "3  2014     5 2014-02-03      2014  36.0\n",
      "4  2014     6 2014-02-10      2014  42.0\n",
      "\n",
      "DataFrame prepared for Prophet - Tail:\n",
      "     Year  Week         ds  Epi_Year     y\n",
      "568  2024    48 2024-11-25      2024  33.0\n",
      "569  2024    49 2024-12-02      2024  49.0\n",
      "570  2024    50 2024-12-09      2024  38.0\n",
      "571  2024    51 2024-12-16      2024  32.0\n",
      "572  2024    52 2024-12-23      2024  36.0\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataframe for Prophet\n",
    "df_national_prophet = df_national.rename(columns={'Date': 'ds', 'total_cases': 'y'})\n",
    "df_national_prophet['ds'] = pd.to_datetime(df_national_prophet['ds'])\n",
    "df_national_prophet = df_national_prophet.sort_values('ds')\n",
    "print(\"DataFrame prepared for Prophet - Head:\")\n",
    "print(df_national_prophet.head())\n",
    "print(\"\")\n",
    "print(\"DataFrame prepared for Prophet - Tail:\")\n",
    "print(df_national_prophet.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "854d61d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_states_original = pd.read_csv('../data/processed/data_processed_v3_NoAcum_Total.csv')\n",
    "df_states_sex_original = pd.read_csv('../data/processed/data_processed_v3_NoAcum_MF.csv')\n",
    "states_list = df_states_original['Entity'].unique().tolist()\n",
    "try:\n",
    "    states_list.remove('National')\n",
    "except ValueError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1a0f5e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared DataFrames for each state:\n",
      "State: Aguascalientes\n",
      "          ds    y\n",
      "0 2014-01-13  0.0\n",
      "1 2014-01-20  0.0\n",
      "2 2014-01-27  0.0\n",
      "3 2014-02-03  0.0\n",
      "4 2014-02-10  0.0\n",
      "\n",
      "State: Baja California\n",
      "          ds    y\n",
      "0 2014-01-13  0.0\n",
      "1 2014-01-20  6.0\n",
      "2 2014-01-27  1.0\n",
      "3 2014-02-03  3.0\n",
      "4 2014-02-10  4.0\n",
      "\n",
      "State: Baja California Sur\n",
      "          ds    y\n",
      "0 2014-01-13  0.0\n",
      "1 2014-01-20  0.0\n",
      "2 2014-01-27  0.0\n",
      "3 2014-02-03  0.0\n",
      "4 2014-02-10  0.0\n",
      "\n",
      "State: Campeche\n",
      "          ds    y\n",
      "0 2014-01-13  0.0\n",
      "1 2014-01-20  0.0\n",
      "2 2014-01-27  1.0\n",
      "3 2014-02-03  1.0\n",
      "4 2014-02-10  3.0\n",
      "\n",
      "State: Chiapas\n",
      "          ds    y\n",
      "0 2014-01-13  0.0\n",
      "1 2014-01-20  0.0\n",
      "2 2014-01-27  1.0\n",
      "3 2014-02-03  1.0\n",
      "4 2014-02-10  2.0\n",
      "\n",
      "State: Chihuahua\n",
      "          ds    y\n",
      "0 2014-01-13  0.0\n",
      "1 2014-01-20  2.0\n",
      "2 2014-01-27  2.0\n",
      "3 2014-02-03  2.0\n",
      "4 2014-02-10  0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataframes for each state\n",
    "dfs_states = {}\n",
    "for state in states_list:\n",
    "    df_state = df_states_original[df_states_original['Entity'] == state].copy()\n",
    "    df_state = df_state.groupby('Date')['total_cases'].sum().reset_index()\n",
    "    df_state = df_state.rename(columns={'Date': 'ds', 'total_cases': 'y'})\n",
    "    df_state['ds'] = pd.to_datetime(df_state['ds'])\n",
    "    df_state = df_state.sort_values('ds')\n",
    "    dfs_states[state] = df_state\n",
    "\n",
    "print(\"Prepared DataFrames for each state:\")\n",
    "for i, (state, df) in enumerate(dfs_states.items()):\n",
    "    print(f\"State: {state}\")\n",
    "    print(df.head())\n",
    "    print(\"\")\n",
    "    if i == 5: \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "dbc606c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared DataFrames for each state:\n",
      "State: ('Aguascalientes', 'M')\n",
      "          ds    y\n",
      "0 2014-01-13  0.0\n",
      "1 2014-01-20  0.0\n",
      "2 2014-01-27  0.0\n",
      "3 2014-02-03  0.0\n",
      "4 2014-02-10  0.0\n",
      "\n",
      "State: ('Aguascalientes', 'F')\n",
      "          ds    y\n",
      "0 2014-01-13  0.0\n",
      "1 2014-01-20  0.0\n",
      "2 2014-01-27  0.0\n",
      "3 2014-02-03  0.0\n",
      "4 2014-02-10  0.0\n",
      "\n",
      "State: ('Baja California', 'M')\n",
      "          ds    y\n",
      "0 2014-01-13  0.0\n",
      "1 2014-01-20  1.0\n",
      "2 2014-01-27  0.0\n",
      "3 2014-02-03  0.0\n",
      "4 2014-02-10  1.0\n",
      "\n",
      "State: ('Baja California', 'F')\n",
      "          ds    y\n",
      "0 2014-01-13  0.0\n",
      "1 2014-01-20  5.0\n",
      "2 2014-01-27  1.0\n",
      "3 2014-02-03  3.0\n",
      "4 2014-02-10  3.0\n",
      "\n",
      "State: ('Baja California Sur', 'M')\n",
      "          ds    y\n",
      "0 2014-01-13  0.0\n",
      "1 2014-01-20  0.0\n",
      "2 2014-01-27  0.0\n",
      "3 2014-02-03  0.0\n",
      "4 2014-02-10  0.0\n",
      "\n",
      "State: ('Baja California Sur', 'F')\n",
      "          ds    y\n",
      "0 2014-01-13  0.0\n",
      "1 2014-01-20  0.0\n",
      "2 2014-01-27  0.0\n",
      "3 2014-02-03  0.0\n",
      "4 2014-02-10  0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataframes for each state and sex\n",
    "dfs_states_sex = {}\n",
    "for state in states_list:\n",
    "    for sex in ['M', 'F']: # 'M' = Male, 'F' = Female\n",
    "        df_ss = df_states_sex_original[df_states_sex_original['Entity'] == state].copy()\n",
    "        df_ss = df_ss.groupby('Date')[sex].sum().reset_index()\n",
    "        df_ss = df_ss.rename(columns={'Date': 'ds', sex: 'y'})\n",
    "        df_ss['ds'] = pd.to_datetime(df_ss['ds'])\n",
    "        df_ss = df_ss.sort_values('ds')\n",
    "        dfs_states_sex[(state, sex)] = df_ss\n",
    "   \n",
    "\n",
    "print(\"Prepared DataFrames for each state:\")\n",
    "for i, (state, df) in enumerate(dfs_states_sex.items()):\n",
    "    print(f\"State: {state}\")\n",
    "    print(df.head())\n",
    "    print(\"\")\n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4156348d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holidays definition\n",
    "years = range(2014, 2030) \n",
    "holidays_list = []\n",
    "for year in years:\n",
    "    holidays_list.append({'ds': f'{year}-12-25', 'holiday': 'Navidad'})\n",
    "    holidays_list.append({'ds': f'{year}-01-01', 'holiday': 'Ano_Nuevo'})\n",
    "    easter_date = dateutil.easter.easter(year)\n",
    "    holidays_list.append({'ds': easter_date.strftime('%Y-%m-%d'), 'holiday': 'Semana_Santa'})\n",
    "    friday_before_easter = easter_date - pd.Timedelta(days=2)\n",
    "    holidays_list.append({'ds': friday_before_easter.strftime('%Y-%m-%d'), 'holiday': 'Viernes_Santo'})\n",
    "\n",
    "# create dataframe once and set Semana_Santa window\n",
    "holidays = pd.DataFrame(holidays_list)\n",
    "holidays.loc[holidays['holiday'] == 'Semana_Santa', 'lower_window'] = -3\n",
    "holidays.loc[holidays['holiday'] == 'Semana_Santa', 'upper_window'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e4d2ba7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrames with Covid-19 indicator added:\n",
      "National DataFrame - Head:\n",
      "   Year  Week         ds  Epi_Year     y  covid_dummy\n",
      "0  2014     2 2014-01-13      2014   4.0            0\n",
      "1  2014     3 2014-01-20      2014  29.0            0\n",
      "2  2014     4 2014-01-27      2014  47.0            0\n",
      "3  2014     5 2014-02-03      2014  36.0            0\n",
      "4  2014     6 2014-02-10      2014  42.0            0\n",
      "\n",
      "State DataFrame Example - Head:\n",
      "State: Aguascalientes\n",
      "          ds    y  covid_dummy\n",
      "0 2014-01-13  0.0            0\n",
      "1 2014-01-20  0.0            0\n",
      "2 2014-01-27  0.0            0\n",
      "3 2014-02-03  0.0            0\n",
      "4 2014-02-10  0.0            0\n",
      "\n",
      "State and Sex DataFrame Example - Head:\n",
      "State and Sex   : ('Aguascalientes', 'M')\n",
      "          ds    y  covid_dummy\n",
      "0 2014-01-13  0.0            0\n",
      "1 2014-01-20  0.0            0\n",
      "2 2014-01-27  0.0            0\n",
      "3 2014-02-03  0.0            0\n",
      "4 2014-02-10  0.0            0\n"
     ]
    }
   ],
   "source": [
    "# Covid-19 Indicator\n",
    "\n",
    "start_covid = pd.Timestamp('2020-03-01')\n",
    "end_covid = pd.Timestamp('2022-12-31') \n",
    "def covid_indicator(date):\n",
    "    if start_covid <= date <= end_covid:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "df_national_prophet['covid_dummy'] = df_national_prophet['ds'].apply(covid_indicator)\n",
    "for state, df_state in dfs_states.items():\n",
    "    df_state['covid_dummy'] = df_state['ds'].apply(covid_indicator)\n",
    "for key, df_ss in dfs_states_sex.items():\n",
    "    df_ss['covid_dummy'] = df_ss['ds'].apply(covid_indicator)\n",
    "\n",
    "print(\"DataFrames with Covid-19 indicator added:\")\n",
    "print(\"National DataFrame - Head:\")\n",
    "print(df_national_prophet.head())\n",
    "print(\"\")\n",
    "print(\"State DataFrame Example - Head:\")\n",
    "example_state = list(dfs_states.keys())[0]\n",
    "print(f\"State: {example_state}\")\n",
    "print(dfs_states[example_state].head())\n",
    "print(\"\")\n",
    "print(\"State and Sex DataFrame Example - Head:\")\n",
    "example_key = list(dfs_states_sex.keys())[0]\n",
    "print(f\"State and Sex   : {example_key}\")\n",
    "print(dfs_states_sex[example_key].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "31f6a705",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:23:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:23:55 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<prophet.forecaster.Prophet at 0x16a79e050>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure and Train Prophet for National Data\n",
    "\n",
    "model_national = Prophet(yearly_seasonality=True, \n",
    "                         weekly_seasonality=False, \n",
    "                         daily_seasonality=False, \n",
    "                         seasonality_mode='multiplicative', \n",
    "                         holidays=holidays, \n",
    "                         changepoint_prior_scale=0.1, # It lets the model detect trend changes moderately\n",
    "                         seasonality_prior_scale=5.0 # It gives us more flexibility in fitting seasonal patterns but with regularization\n",
    ")\n",
    "model_national.add_regressor('covid_dummy')\n",
    "model_national.fit(df_national_prophet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4a020718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecast for National Data - Tail:\n",
      "            ds       yhat  yhat_lower  yhat_upper\n",
      "826 2029-11-19  29.548149 -132.907432  179.561455\n",
      "827 2029-11-26  26.858353 -130.295924  185.210891\n",
      "828 2029-12-03  27.432981 -127.989325  182.122020\n",
      "829 2029-12-10  29.677390 -125.406158  184.661294\n",
      "830 2029-12-17  28.822117 -121.512353  188.996073\n"
     ]
    }
   ],
   "source": [
    "# Create dataframe for future predictions (5 years ahead)\n",
    "future_national = model_national.make_future_dataframe(periods=260, freq='W-MON') # Weekly on Mondays\n",
    "future_national['covid_dummy'] = future_national['ds'].apply(covid_indicator)\n",
    "forecast_national = model_national.predict(future_national)\n",
    "\n",
    "print(\"Forecast for National Data - Tail:\")\n",
    "print(forecast_national[['ds', 'yhat','yhat_lower','yhat_upper']].tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2c1fa99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:23:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:23:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:23:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:23:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:23:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:23:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:23:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:23:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:23:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:23:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:23:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:23:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:23:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:23:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:01 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:01 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:06 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:10 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:10 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:11 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:11 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:12 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "# Configure and fit Prophet model for state-level data\n",
    "models_states = {}\n",
    "forecasts_states = {}\n",
    "for state, df_state in dfs_states.items():\n",
    "    m = Prophet(\n",
    "    yearly_seasonality=True, \n",
    "    weekly_seasonality=False,\n",
    "    daily_seasonality=False,\n",
    "    seasonality_mode='multiplicative',\n",
    "    holidays=holidays,\n",
    "    changepoint_prior_scale=0.1,\n",
    "    seasonality_prior_scale=5.0\n",
    "    )\n",
    "    m.add_regressor('covid_dummy')\n",
    "    m.fit(df_state)\n",
    "\n",
    "    models_states[state] = m\n",
    "    future = m.make_future_dataframe(periods=260, freq='W-MON')\n",
    "    future['covid_dummy'] = future['ds'].apply(covid_indicator)\n",
    "    forecast = m.predict(future)\n",
    "    forecasts_states[state] = forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "48e4a9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:24:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:13 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:13 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:13 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:15 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:15 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:15 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:16 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:16 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:17 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:17 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:17 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:17 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:18 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:18 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:19 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:19 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:20 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:20 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:21 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:21 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:22 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:22 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:23 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:23 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:24 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:25 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:25 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:26 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:26 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:28 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:28 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:30 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:31 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:32 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:32 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:33 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:34 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:35 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:36 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:36 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:37 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:38 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:38 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:39 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:39 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:40 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:40 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:41 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:42 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:42 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:43 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:43 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:43 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:43 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:44 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:44 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:45 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:45 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:46 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:46 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:47 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:47 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:48 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:48 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:49 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "# Create and train Prophet models for each state and sex\n",
    "models_states_sex = {}\n",
    "forecasts_states_sex = {}\n",
    "for (state, sex), df_ss in dfs_states_sex.items():\n",
    "    m = Prophet(\n",
    "    yearly_seasonality=True, \n",
    "    weekly_seasonality=False,\n",
    "    daily_seasonality=False,\n",
    "    seasonality_mode='multiplicative',\n",
    "    holidays=holidays,\n",
    "    changepoint_prior_scale=0.1,\n",
    "    seasonality_prior_scale=5.0\n",
    "    )\n",
    "    m.add_regressor('covid_dummy')\n",
    "    m.fit(df_ss)\n",
    "    models_states_sex[(state, sex)] = m\n",
    "    future = m.make_future_dataframe(periods=260, freq='W-MON')\n",
    "    future['covid_dummy'] = future['ds'].apply(covid_indicator)\n",
    "    forecast = m.predict(future)\n",
    "    forecasts_states_sex[(state, sex)] = forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334a0034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97, 260)\n"
     ]
    }
   ],
   "source": [
    "# Structure forecasts into a better format that will be used later for reconciliation \n",
    "H = 260 # Forecast horizon in weeks\n",
    "y_base = []\n",
    "\n",
    "yhat_national = forecast_national['yhat'].iloc[-260:].values\n",
    "yhat_states = {}\n",
    "for state in states_list:\n",
    "    yhat_states[state] = forecasts_states[state]['yhat'].iloc[-260:].values\n",
    "\n",
    "yhat_states_sex = {}\n",
    "for state in states_list:\n",
    "    for sex in ['M', 'F']:\n",
    "        yhat_states_sex[(state, sex)] = forecasts_states_sex[(state, sex)]['yhat'].iloc[-260:].values\n",
    "\n",
    "# National level\n",
    "y_base.append(yhat_national)\n",
    "# State level\n",
    "for state in states_list:\n",
    "    y_base.append(yhat_states[state])\n",
    "# State and sex level\n",
    "for state in states_list:\n",
    "    y_base.append(yhat_states_sex[(state, 'M')])\n",
    "    y_base.append(yhat_states_sex[(state, 'F')])\n",
    "\n",
    "Y_base = np.vstack(y_base)  \n",
    "print(Y_base.shape)  # Shape: (97, 260) -> 1 National + 32 States + 32 States * 2 Genders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc62ab2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summing matrix S shape: (97, 64)\n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Reconciliation with MinT\n",
    "n = Y_base.shape[0]  # Total number of series\n",
    "m = 64  # Number of series bottom\n",
    "# Construct the summing matrix S\n",
    "S = np.zeros((n, m))\n",
    "# National level\n",
    "S[0, :] = 1\n",
    "\n",
    "# State level\n",
    "for i, state in enumerate(states_list):\n",
    "    col_M = 2*(i-1) # Males of state i \n",
    "    col_F = 2*(i-1) + 1 # Females of state i\n",
    "    S[i, col_M] = 1\n",
    "    S[i, col_F] = 1\n",
    "\n",
    "# State and sex level\n",
    "for j in range(m):\n",
    "    S[1 + len(states_list)+j, j] = 1 # Bottom level series\n",
    "\n",
    "print(\"Summing matrix S shape:\", S.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b5f5fb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "National reconciliated week 1: 25.730400772052114\n",
      "Sum states week 1: 25.64138021460853\n",
      "\n",
      "--- State: Aguascalientes\n",
      "\tState reconciliated week 1: 0.3737081159706862\n",
      "\tSum state reconciliated week 1: 0.3737081159706862\n",
      "--- State: Baja California\n",
      "\tState reconciliated week 1: 0.7569475957974903\n",
      "\tSum state reconciliated week 1: 0.7569475957974903\n",
      "--- State: Baja California Sur\n",
      "\tState reconciliated week 1: 0.12963150716596786\n",
      "\tSum state reconciliated week 1: 0.12963150716596786\n",
      "--- State: Campeche\n",
      "\tState reconciliated week 1: 0.09488922753251938\n",
      "\tSum state reconciliated week 1: 0.09488922753251938\n",
      "--- State: Chiapas\n",
      "\tState reconciliated week 1: 0.7276687157920506\n",
      "\tSum state reconciliated week 1: 0.7276687157920506\n",
      "--- State: Chihuahua\n",
      "\tState reconciliated week 1: 2.4607421054176606\n",
      "\tSum state reconciliated week 1: 2.4607421054176606\n"
     ]
    }
   ],
   "source": [
    "# Proyection matrix for OLS reconciliation\n",
    "inv_Sst = np.linalg.inv(S.T @ S) \n",
    "G_ols = inv_Sst @ S.T\n",
    "Y_recon_bottom = G_ols @ Y_base\n",
    "Y_reconciled = S @ Y_recon_bottom # Forecast Matrix (97 x H) \n",
    "\n",
    "# Now we can verify that the reconciliation worked\n",
    "# Check National level\n",
    "national_reconciliated_week1 = Y_reconciled[0, 0]\n",
    "sum_states_week1 = np.sum(Y_reconciled[1:1+len(states_list), 0])\n",
    "print(f\"National reconciliated week 1: {national_reconciliated_week1}\")\n",
    "print(f\"Sum states week 1: {sum_states_week1}\")\n",
    "\n",
    "print(\"\")\n",
    "# Check State level\n",
    "for i, state in enumerate(states_list):\n",
    "    state_reconciliated_week1 = Y_reconciled[1 + i, 0]\n",
    "    col_M = 2*i\n",
    "    col_F = 2*i + 1\n",
    "    sum_state_reconciliated_week1 = Y_reconciled[1 + len(states_list) + col_M, 0] + Y_reconciled[1 + len(states_list) + col_F, 0]\n",
    "    print(f\"--- State: {state}\")\n",
    "    print(f\"\\tState reconciliated week 1: {state_reconciliated_week1}\")\n",
    "    print(f\"\\tSum state reconciliated week 1: {sum_state_reconciliated_week1}\")\n",
    "    if i == 5:  # Just check first 6 states\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
