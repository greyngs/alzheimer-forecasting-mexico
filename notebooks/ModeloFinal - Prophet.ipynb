{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3bea63c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dateutil.easter\n",
    "from prophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3633a3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Week</th>\n",
       "      <th>Date</th>\n",
       "      <th>Epi_Year</th>\n",
       "      <th>total_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>2014-01-13</td>\n",
       "      <td>2014</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>2014-01-20</td>\n",
       "      <td>2014</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>2014-01-27</td>\n",
       "      <td>2014</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>2014-02-03</td>\n",
       "      <td>2014</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>2014-02-10</td>\n",
       "      <td>2014</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Week        Date  Epi_Year  total_cases\n",
       "0  2014     2  2014-01-13      2014          4.0\n",
       "1  2014     3  2014-01-20      2014         29.0\n",
       "2  2014     4  2014-01-27      2014         47.0\n",
       "3  2014     5  2014-02-03      2014         36.0\n",
       "4  2014     6  2014-02-10      2014         42.0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_national = pd.read_csv(\n",
    "    '../data/processed/data_processed_v3_National_NoAcum_Total.csv')\n",
    "df_national.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fe663b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame prepared for Prophet - Head:\n",
      "   Year  Week         ds  Epi_Year     y\n",
      "0  2014     2 2014-01-13      2014   4.0\n",
      "1  2014     3 2014-01-20      2014  29.0\n",
      "2  2014     4 2014-01-27      2014  47.0\n",
      "3  2014     5 2014-02-03      2014  36.0\n",
      "4  2014     6 2014-02-10      2014  42.0\n",
      "\n",
      "DataFrame prepared for Prophet - Tail:\n",
      "     Year  Week         ds  Epi_Year     y\n",
      "568  2024    48 2024-11-25      2024  33.0\n",
      "569  2024    49 2024-12-02      2024  49.0\n",
      "570  2024    50 2024-12-09      2024  38.0\n",
      "571  2024    51 2024-12-16      2024  32.0\n",
      "572  2024    52 2024-12-23      2024  36.0\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataframe for Prophet\n",
    "df_national_prophet = df_national.rename(columns={'Date': 'ds', 'total_cases': 'y'})\n",
    "df_national_prophet['ds'] = pd.to_datetime(df_national_prophet['ds'])\n",
    "df_national_prophet = df_national_prophet.sort_values('ds')\n",
    "print(\"DataFrame prepared for Prophet - Head:\")\n",
    "print(df_national_prophet.head())\n",
    "print(\"\")\n",
    "print(\"DataFrame prepared for Prophet - Tail:\")\n",
    "print(df_national_prophet.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "854d61d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_states_original = pd.read_csv('../data/processed/data_processed_v3_NoAcum_Total.csv')\n",
    "df_states_sex_original = pd.read_csv('../data/processed/data_processed_v3_NoAcum_MF.csv')\n",
    "states_list = df_states_original['Entity'].unique().tolist()\n",
    "try:\n",
    "    states_list.remove('National')\n",
    "except ValueError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1a0f5e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared DataFrames for each state:\n",
      "State: Aguascalientes\n",
      "          ds    y\n",
      "0 2014-01-13  0.0\n",
      "1 2014-01-20  0.0\n",
      "2 2014-01-27  0.0\n",
      "3 2014-02-03  0.0\n",
      "4 2014-02-10  0.0\n",
      "\n",
      "State: Baja California\n",
      "          ds    y\n",
      "0 2014-01-13  0.0\n",
      "1 2014-01-20  6.0\n",
      "2 2014-01-27  1.0\n",
      "3 2014-02-03  3.0\n",
      "4 2014-02-10  4.0\n",
      "\n",
      "State: Baja California Sur\n",
      "          ds    y\n",
      "0 2014-01-13  0.0\n",
      "1 2014-01-20  0.0\n",
      "2 2014-01-27  0.0\n",
      "3 2014-02-03  0.0\n",
      "4 2014-02-10  0.0\n",
      "\n",
      "State: Campeche\n",
      "          ds    y\n",
      "0 2014-01-13  0.0\n",
      "1 2014-01-20  0.0\n",
      "2 2014-01-27  1.0\n",
      "3 2014-02-03  1.0\n",
      "4 2014-02-10  3.0\n",
      "\n",
      "State: Chiapas\n",
      "          ds    y\n",
      "0 2014-01-13  0.0\n",
      "1 2014-01-20  0.0\n",
      "2 2014-01-27  1.0\n",
      "3 2014-02-03  1.0\n",
      "4 2014-02-10  2.0\n",
      "\n",
      "State: Chihuahua\n",
      "          ds    y\n",
      "0 2014-01-13  0.0\n",
      "1 2014-01-20  2.0\n",
      "2 2014-01-27  2.0\n",
      "3 2014-02-03  2.0\n",
      "4 2014-02-10  0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataframes for each state\n",
    "dfs_states = {}\n",
    "for state in states_list:\n",
    "    df_state = df_states_original[df_states_original['Entity'] == state].copy()\n",
    "    df_state = df_state.groupby('Date')['total_cases'].sum().reset_index()\n",
    "    df_state = df_state.rename(columns={'Date': 'ds', 'total_cases': 'y'})\n",
    "    df_state['ds'] = pd.to_datetime(df_state['ds'])\n",
    "    df_state = df_state.sort_values('ds')\n",
    "    dfs_states[state] = df_state\n",
    "\n",
    "print(\"Prepared DataFrames for each state:\")\n",
    "for i, (state, df) in enumerate(dfs_states.items()):\n",
    "    print(f\"State: {state}\")\n",
    "    print(df.head())\n",
    "    print(\"\")\n",
    "    if i == 5: \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dbc606c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared DataFrames for each state:\n",
      "State: ('Aguascalientes', 'M')\n",
      "          ds    y\n",
      "0 2014-01-13  0.0\n",
      "1 2014-01-20  0.0\n",
      "2 2014-01-27  0.0\n",
      "3 2014-02-03  0.0\n",
      "4 2014-02-10  0.0\n",
      "\n",
      "State: ('Aguascalientes', 'F')\n",
      "          ds    y\n",
      "0 2014-01-13  0.0\n",
      "1 2014-01-20  0.0\n",
      "2 2014-01-27  0.0\n",
      "3 2014-02-03  0.0\n",
      "4 2014-02-10  0.0\n",
      "\n",
      "State: ('Baja California', 'M')\n",
      "          ds    y\n",
      "0 2014-01-13  0.0\n",
      "1 2014-01-20  1.0\n",
      "2 2014-01-27  0.0\n",
      "3 2014-02-03  0.0\n",
      "4 2014-02-10  1.0\n",
      "\n",
      "State: ('Baja California', 'F')\n",
      "          ds    y\n",
      "0 2014-01-13  0.0\n",
      "1 2014-01-20  5.0\n",
      "2 2014-01-27  1.0\n",
      "3 2014-02-03  3.0\n",
      "4 2014-02-10  3.0\n",
      "\n",
      "State: ('Baja California Sur', 'M')\n",
      "          ds    y\n",
      "0 2014-01-13  0.0\n",
      "1 2014-01-20  0.0\n",
      "2 2014-01-27  0.0\n",
      "3 2014-02-03  0.0\n",
      "4 2014-02-10  0.0\n",
      "\n",
      "State: ('Baja California Sur', 'F')\n",
      "          ds    y\n",
      "0 2014-01-13  0.0\n",
      "1 2014-01-20  0.0\n",
      "2 2014-01-27  0.0\n",
      "3 2014-02-03  0.0\n",
      "4 2014-02-10  0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataframes for each state and sex\n",
    "dfs_states_sex = {}\n",
    "for state in states_list:\n",
    "    for sex in ['M', 'F']: # 'M' = Male, 'F' = Female\n",
    "        df_ss = df_states_sex_original[df_states_sex_original['Entity'] == state].copy()\n",
    "        df_ss = df_ss.groupby('Date')[sex].sum().reset_index()\n",
    "        df_ss = df_ss.rename(columns={'Date': 'ds', sex: 'y'})\n",
    "        df_ss['ds'] = pd.to_datetime(df_ss['ds'])\n",
    "        df_ss = df_ss.sort_values('ds')\n",
    "        dfs_states_sex[(state, sex)] = df_ss\n",
    "   \n",
    "\n",
    "print(\"Prepared DataFrames for each state:\")\n",
    "for i, (state, df) in enumerate(dfs_states_sex.items()):\n",
    "    print(f\"State: {state}\")\n",
    "    print(df.head())\n",
    "    print(\"\")\n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4156348d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holidays definition\n",
    "years = range(2014, 2030) \n",
    "holidays_list = []\n",
    "for year in years:\n",
    "    holidays_list.append({'ds': f'{year}-12-25', 'holiday': 'Navidad'})\n",
    "    holidays_list.append({'ds': f'{year}-01-01', 'holiday': 'Ano_Nuevo'})\n",
    "    easter_date = dateutil.easter.easter(year)\n",
    "    holidays_list.append({'ds': easter_date.strftime('%Y-%m-%d'), 'holiday': 'Semana_Santa'})\n",
    "    friday_before_easter = easter_date - pd.Timedelta(days=2)\n",
    "    holidays_list.append({'ds': friday_before_easter.strftime('%Y-%m-%d'), 'holiday': 'Viernes_Santo'})\n",
    "\n",
    "# create dataframe once and set Semana_Santa window\n",
    "holidays = pd.DataFrame(holidays_list)\n",
    "holidays.loc[holidays['holiday'] == 'Semana_Santa', 'lower_window'] = -3\n",
    "holidays.loc[holidays['holiday'] == 'Semana_Santa', 'upper_window'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e4d2ba7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrames with Covid-19 indicator added:\n",
      "National DataFrame - Head:\n",
      "   Year  Week         ds  Epi_Year     y  covid_dummy\n",
      "0  2014     2 2014-01-13      2014   4.0            0\n",
      "1  2014     3 2014-01-20      2014  29.0            0\n",
      "2  2014     4 2014-01-27      2014  47.0            0\n",
      "3  2014     5 2014-02-03      2014  36.0            0\n",
      "4  2014     6 2014-02-10      2014  42.0            0\n",
      "\n",
      "State DataFrame Example - Head:\n",
      "State: Aguascalientes\n",
      "          ds    y  covid_dummy\n",
      "0 2014-01-13  0.0            0\n",
      "1 2014-01-20  0.0            0\n",
      "2 2014-01-27  0.0            0\n",
      "3 2014-02-03  0.0            0\n",
      "4 2014-02-10  0.0            0\n",
      "\n",
      "State and Sex DataFrame Example - Head:\n",
      "State and Sex   : ('Aguascalientes', 'M')\n",
      "          ds    y  covid_dummy\n",
      "0 2014-01-13  0.0            0\n",
      "1 2014-01-20  0.0            0\n",
      "2 2014-01-27  0.0            0\n",
      "3 2014-02-03  0.0            0\n",
      "4 2014-02-10  0.0            0\n"
     ]
    }
   ],
   "source": [
    "# Covid-19 Indicator\n",
    "\n",
    "start_covid = pd.Timestamp('2020-03-01')\n",
    "end_covid = pd.Timestamp('2022-12-31') \n",
    "def covid_indicator(date):\n",
    "    if start_covid <= date <= end_covid:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "df_national_prophet['covid_dummy'] = df_national_prophet['ds'].apply(covid_indicator)\n",
    "for state, df_state in dfs_states.items():\n",
    "    df_state['covid_dummy'] = df_state['ds'].apply(covid_indicator)\n",
    "for key, df_ss in dfs_states_sex.items():\n",
    "    df_ss['covid_dummy'] = df_ss['ds'].apply(covid_indicator)\n",
    "\n",
    "print(\"DataFrames with Covid-19 indicator added:\")\n",
    "print(\"National DataFrame - Head:\")\n",
    "print(df_national_prophet.head())\n",
    "print(\"\")\n",
    "print(\"State DataFrame Example - Head:\")\n",
    "example_state = list(dfs_states.keys())[0]\n",
    "print(f\"State: {example_state}\")\n",
    "print(dfs_states[example_state].head())\n",
    "print(\"\")\n",
    "print(\"State and Sex DataFrame Example - Head:\")\n",
    "example_key = list(dfs_states_sex.keys())[0]\n",
    "print(f\"State and Sex   : {example_key}\")\n",
    "print(dfs_states_sex[example_key].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f6a705",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:57:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:57:58 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<prophet.forecaster.Prophet at 0x16a64e650>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure and Train Prophet for National Data\n",
    "\n",
    "model_national = Prophet(yearly_seasonality=True, \n",
    "                         weekly_seasonality=False, \n",
    "                         daily_seasonality=False, \n",
    "                         seasonality_mode='multiplicative', \n",
    "                         holidays=holidays, \n",
    "                         changepoint_prior_scale=0.1, # It lets the model detect trend changes moderately\n",
    "                         seasonality_prior_scale=5.0 # It gives us more flexibility in fitting seasonal patterns but with regularization\n",
    ")\n",
    "model_national.add_regressor('covid_dummy')\n",
    "model_national.fit(df_national_prophet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4a020718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecast for National Data - Tail:\n",
      "            ds       yhat  yhat_lower  yhat_upper\n",
      "826 2029-11-19  29.548149 -119.712000  180.857092\n",
      "827 2029-11-26  26.858353 -134.538647  185.543358\n",
      "828 2029-12-03  27.432981 -138.047136  175.732851\n",
      "829 2029-12-10  29.677390 -120.108457  196.886891\n",
      "830 2029-12-17  28.822117 -125.734016  191.490428\n"
     ]
    }
   ],
   "source": [
    "# Create dataframe for future predictions (5 years ahead)\n",
    "future_national = model_national.make_future_dataframe(periods=260, freq='W-MON') # Weekly on Mondays\n",
    "future_national['covid_dummy'] = future_national['ds'].apply(covid_indicator)\n",
    "forecast_national = model_national.predict(future_national)\n",
    "\n",
    "print(\"Forecast for National Data - Tail:\")\n",
    "print(forecast_national[['ds', 'yhat','yhat_lower','yhat_upper']].tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1fa99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:04:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:04:39 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:04:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:04:40 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:04:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:04:40 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:04:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:04:41 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:04:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:04:42 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:04:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:04:42 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:04:43 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:04:43 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:04:43 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:04:43 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:04:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:04:44 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:04:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:04:44 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:04:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:04:45 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:04:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:04:46 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:04:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:04:46 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:04:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:04:47 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:04:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:04:48 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:04:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:04:50 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:04:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:04:51 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:04:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:04:51 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:04:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:04:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:04:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:04:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:04:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:04:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:04:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:04:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:04:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:04:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:04:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:04:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:04:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:04:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:04:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:04:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:04:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:04:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:04:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:04:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:04:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:04:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:04:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:04:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:05:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:05:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:05:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:05:02 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "# Configure and fit Prophet model for state-level data\n",
    "models_states = {}\n",
    "forecasts_states = {}\n",
    "for state, df_state in dfs_states.items():\n",
    "    m = Prophet(\n",
    "    yearly_seasonality=True, \n",
    "    weekly_seasonality=False,\n",
    "    daily_seasonality=False,\n",
    "    seasonality_mode='multiplicative',\n",
    "    holidays=holidays,\n",
    "    changepoint_prior_scale=0.1,\n",
    "    seasonality_prior_scale=5.0\n",
    "    )\n",
    "    m.add_regressor('covid_dummy')\n",
    "    m.fit(df_state)\n",
    "\n",
    "    models_states[state] = m\n",
    "    future = m.make_future_dataframe(periods=260, freq='W-MON')\n",
    "    future['covid_dummy'] = future['ds'].apply(covid_indicator)\n",
    "    forecast = m.predict(future)\n",
    "    forecasts_states[state] = forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "48e4a9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:08:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:06 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:10 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:11 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:13 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:13 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:15 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:16 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:17 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:18 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:19 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:20 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:21 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:22 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:23 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:24 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:25 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:25 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:26 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:26 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:28 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:28 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:30 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:32 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:33 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:33 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:33 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:34 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:34 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:35 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:36 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:36 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:36 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:37 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:37 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:38 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:39 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:39 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:40 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:40 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:41 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:41 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:41 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:42 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:43 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:43 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:45 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:45 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:46 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:46 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:47 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:47 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:48 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:48 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:49 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:50 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:50 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:51 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:51 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:08:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:53 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "# Create and train Prophet models for each state and sex\n",
    "models_states_sex = {}\n",
    "forecasts_states_sex = {}\n",
    "for (state, sex), df_ss in dfs_states_sex.items():\n",
    "    m = Prophet(\n",
    "    yearly_seasonality=True, \n",
    "    weekly_seasonality=False,\n",
    "    daily_seasonality=False,\n",
    "    seasonality_mode='multiplicative',\n",
    "    holidays=holidays,\n",
    "    changepoint_prior_scale=0.1,\n",
    "    seasonality_prior_scale=5.0\n",
    "    )\n",
    "    m.add_regressor('covid_dummy')\n",
    "    m.fit(df_ss)\n",
    "    models_states_sex[(state, sex)] = m\n",
    "    future = m.make_future_dataframe(periods=260, freq='W-MON')\n",
    "    future['covid_dummy'] = future['ds'].apply(covid_indicator)\n",
    "    forecast = m.predict(future)\n",
    "    forecasts_states_sex[(state, sex)] = forecast"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
